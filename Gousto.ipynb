{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozO23tcN4kZ3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import random\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import choix\n",
        "import networkx as nx\n",
        "import time\n",
        "from pandas.core.frame import DataFrame\n",
        "from itertools import combinations\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "SEED=2022\n",
        "def seed_all(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_all(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU1_AK_d4kaD"
      },
      "source": [
        "# 1. Data preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HadbKNuD4kaI"
      },
      "source": [
        "## 1.1 View data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27JMYtNc4kaI"
      },
      "outputs": [],
      "source": [
        "# import dataset\n",
        "battle = pd.read_csv('battle.csv')\n",
        "recipe = pd.read_excel('recipe.xlsx')\n",
        "order = pd.read_csv('order.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HzOd2gI4kaJ"
      },
      "outputs": [],
      "source": [
        "print(battle.shape)\n",
        "print(recipe.shape)\n",
        "print(order.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQOOIGa24kaP"
      },
      "source": [
        "## 1.2 Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjl43iNn4kaP"
      },
      "outputs": [],
      "source": [
        "#Missing values\n",
        "print(battle.isnull().any())\n",
        "print('\\n')\n",
        "print(recipe.isnull().any())\n",
        "print('\\n')\n",
        "print(order.isnull().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "kYuy-VQ-4kaQ"
      },
      "outputs": [],
      "source": [
        "battle.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6DgED824kaQ"
      },
      "outputs": [],
      "source": [
        "recipe.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCjd1EvT4kaR"
      },
      "outputs": [],
      "source": [
        "recipe.isnull().sum()/3047"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xLG3Eqh4kaR"
      },
      "outputs": [],
      "source": [
        "#drop missing values: records with missing anonymised_user_id in battle dataset\n",
        "battle.dropna(axis=0, how='any', inplace=True)\n",
        "battle.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-v3VK74kaS"
      },
      "source": [
        "1. battle.csv: anonymised_user_id has missing values,I can drop those lines directly.\n",
        "2. recipe.xlsx: recipe_name has no missing values, and I can use it to identify each recipe. \n",
        "3. order.csv: There are no missing values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(battle.shape)\n",
        "print(recipe.shape)\n",
        "print(order.shape)"
      ],
      "metadata": {
        "id": "dkwiUrvsAB6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_info=battle.groupby('anonymised_user_id',as_index=False).count()\n",
        "user_info=user_info[['anonymised_user_id','num_of_battles']]\n",
        "# add a column 'user_id'\n",
        "user_info['user_id']=np.arange(0,user_info.shape[0])\n",
        "battle=pd.merge(battle, user_info, how = 'inner', on='anonymised_user_id')"
      ],
      "metadata": {
        "id": "492C_Zc-AGC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# how many users took this battle game? how many recipes? and how many comparison totally?\n",
        "print('The total number of comparision:', battle.shape [0])\n",
        "user = list(set(battle.anonymised_user_id.unique()))\n",
        "print('The total number of users: ', len(user))\n",
        "item1 = list(np.sort(list(set(battle.recipe_1.unique()))))\n",
        "item2 = list(np.sort(list(set(battle.recipe_2.unique()))))\n",
        "if item1 == item2 : \n",
        "    print('The total number of recipes: ', len(item1))"
      ],
      "metadata": {
        "id": "lvYWo7egAR-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9nIMYvu4kaS"
      },
      "source": [
        "## 1.3 Feature processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geG0rZmQ4kaT"
      },
      "source": [
        "### 1.Battle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1wr9GFL4kaT"
      },
      "outputs": [],
      "source": [
        "#Transform ‘anonymised_user_id’ from float to int\n",
        "battle['anonymised_user_id']=battle['anonymised_user_id'].apply(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOEQdbC64kaU"
      },
      "source": [
        "### 2. Recipe dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZO3-C8t4kaU"
      },
      "outputs": [],
      "source": [
        "# add item_id:[0,1,2,3..]\n",
        "recipe['item_id']= np.arange(0,recipe.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZJLupIM4kaU"
      },
      "outputs": [],
      "source": [
        "# Grouping preparation_time_for_2\n",
        "recipe['preparation_time_for_2']=pd.cut(recipe['preparation_time_for_2'],[0,20,40,60,80,100,120],\n",
        "                                        labels=['(0-20]','(20-40]','(40-60]','(60-80]','(80-100]','(100-120]'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGvD189b4kaV"
      },
      "outputs": [],
      "source": [
        "def String_Split(string, separators):\n",
        "    result_split = [string]\n",
        "    for sep in separators:\n",
        "        string_temp = []\n",
        "        list(\n",
        "                map(\n",
        "                    lambda sub_string: string_temp.extend(sub_string.split(sep)),\n",
        "                    result_split\n",
        "                    )\n",
        "                )\n",
        "        result_split = string_temp\n",
        "\n",
        "    return result_split\n",
        "\n",
        "\n",
        "def dish_types_to_category(df):\n",
        "    d= {item :[] for item in dish_types}\n",
        "    \n",
        "    def f(row):\n",
        "        dish = String_Split(str(row.dish_types), ['|','&','/'])\n",
        "        for item in dish_types:\n",
        "            if item in dish:\n",
        "                d[item].append(1)\n",
        "            else:\n",
        "                d[item].append(0)\n",
        "\n",
        "                \n",
        "    df.apply(f, axis=1)\n",
        "    # add dish category\n",
        "    dish_df = pd.DataFrame(d, columns=dish_types)\n",
        "    df = pd.concat([df, dish_df], axis=1)\n",
        "    return df\n",
        "\n",
        "def dish_to_category(df):\n",
        "    d= {item :[] for item in dish_categories}\n",
        "    \n",
        "    def f(row):\n",
        "        dish = String_Split(str(row.dish_categories), ['|','&','/'])\n",
        "        for item in dish_categories:\n",
        "            if item in dish:\n",
        "                d[item].append(1)\n",
        "            else:\n",
        "                d[item].append(0)\n",
        "    df.apply(f, axis=1)\n",
        "    # add dish category\n",
        "    dish_df = pd.DataFrame(d, columns=dish_categories)\n",
        "    df = pd.concat([df, dish_df], axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def health_to_category(df):\n",
        "    d = {item :[] for item in health_types}\n",
        "    \n",
        "    def f(row):\n",
        "        health = str(row.health_attributes).split('|')\n",
        "        for item in health_types:\n",
        "            if item in health:\n",
        "                d[item].append(1)\n",
        "            else:\n",
        "                d[item].append(0)\n",
        "\n",
        "    # create health category dict\n",
        "    df.apply(f, axis=1)\n",
        "    \n",
        "    # add health category\n",
        "    health_df = pd.DataFrame(d, columns=health_types)\n",
        "    df = pd.concat([df, health_df], axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI8GVc9o4kaV"
      },
      "outputs": [],
      "source": [
        "# dish_types\n",
        "dish_types = ['BBQ','Burger','Sandwich','Hotdog','Tacos','Pasta','Roast','Wraps','Pie',\n",
        "              'Soya','Curry','Burritos','Pizza',\n",
        "              'Dal','Chowder','Gnocchi','Laksa',\n",
        "              'Risotto','Stew','Stir Fry','Pilaf','Tray Bake',]\n",
        "recipe = dish_types_to_category(recipe)\n",
        "\n",
        "# dish_categories\n",
        "dish_categories=['Finger food','Oven','Salads','Stove top','bowl food','Protein','Veg','Soups']\n",
        "recipe = dish_to_category(recipe)\n",
        "\n",
        "# health_attributes\n",
        "health_types = ['Health Exception','Healthy','Low Cal','Low Carb','Not Healthy','Wholegrain']\n",
        "recipe = health_to_category(recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6SG4hpx4kaV"
      },
      "outputs": [],
      "source": [
        "# Choose necessary features from recipe dataset\n",
        "rf=recipe[['recipe_name','item_id','recipe_uuid','preparation_time_for_2','cuisine_name',\n",
        "           'main_carb_name','spice_level','protein_name','protein_category_name','BBQ',\n",
        "       'Burger', 'Sandwich', 'Hotdog', 'Tacos', 'Pasta', 'Roast', 'Wraps',\n",
        "       'Pie', 'Soya', 'Curry', 'Burritos', 'Pizza', 'Dal', 'Chowder',\n",
        "       'Gnocchi', 'Laksa', 'Risotto', 'Stew', 'Stir Fry', 'Pilaf', 'Tray Bake',\n",
        "       'Finger food', 'Oven', 'Salads', 'Stove top', 'bowl food', 'Protein',\n",
        "       'Veg', 'Soups', 'Health Exception', 'Healthy', 'Low Cal', 'Low Carb',\n",
        "       'Not Healthy', 'Wholegrain']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eApfgph94kaW"
      },
      "outputs": [],
      "source": [
        "# unify carb name for same carb\n",
        "# Basmati\n",
        "f = lambda s: 'Basmati' if 'Basmati' in str(s['main_carb_name'])  else s['main_carb_name']\n",
        "rf['main_carb_name'] = rf.apply(f, axis=1)\n",
        "# Brown rice\n",
        "f2 = lambda s: 'Brown rice' if 'Brown rice' in str(s['main_carb_name'])  else s['main_carb_name']\n",
        "rf['main_carb_name'] = rf.apply(f2, axis=1)\n",
        "# Pizza base\n",
        "f3 = lambda s: 'Pizza Base' if 'Pizza Base' in str(s['main_carb_name'])  else s['main_carb_name']\n",
        "rf['main_carb_name'] = rf.apply(f3, axis=1)\n",
        "#None\n",
        "f4 = lambda s: None if str(s['main_carb_name'])=='None' else s['main_carb_name']\n",
        "rf['main_carb_name'] = rf.apply(f4, axis=1)\n",
        "# None in protein_name\n",
        "f5 = lambda s: None if str(s['protein_name'])=='None' else s['protein_name']\n",
        "rf['protein_name'] = rf.apply(f5, axis=1)\n",
        "# None in protein_category_name\n",
        "f6 = lambda s: None if str(s['protein_category_name'])=='None' else s['protein_category_name']\n",
        "rf['protein_category_name'] = rf.apply(f6, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5V0e1vl4kaW"
      },
      "outputs": [],
      "source": [
        "rf[['cuisine_name','main_carb_name','spice_level','protein_name','protein_category_name']]=rf[['cuisine_name','main_carb_name','spice_level','protein_name','protein_category_name']].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I9xz1cl4kaX"
      },
      "source": [
        "### 3. Order dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge Recipe dataset and Order dataset on uuid\n",
        "order2=pd.merge(order, recipe, how = 'left', left_on='menu_recipe_uuid', right_on = 'recipe_uuid')\n",
        "order2=order2[['anonymised_user_id','period_id', 'menu_recipe_id', 'menu_recipe_uuid',\n",
        "               'recipe_name','ordered','item_id']]"
      ],
      "metadata": {
        "id": "c11OrqHgdw2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose necessary columns\n",
        "order2=pd.merge(order2, user_info, how = 'left', left_on='anonymised_user_id', right_on = 'anonymised_user_id')"
      ],
      "metadata": {
        "id": "6NuOzYtqdzKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXMvBBpQ4kaY"
      },
      "source": [
        "# 2. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZyt1Tly4kaY"
      },
      "source": [
        "## 2.1 BT model-Obtain users' preferences for 30 recipes entered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bloXWvGQ4kaZ"
      },
      "source": [
        "This function computes the maximum-likelihood (ML) estimate of model parameters given pairwise-comparison data, using the Newton-CG algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yABqAWkH4kaZ"
      },
      "outputs": [],
      "source": [
        "t=list(recipe.recipe_name)\n",
        "data= collections.defaultdict(list)\n",
        "for i in range(len(battle.recipe_1)):\n",
        "    if battle.chosen_position[i]==1:\n",
        "        el = (t.index(battle.recipe_1[i]), t.index(battle.recipe_2[i]))\n",
        "        \n",
        "    else:\n",
        "        el = (t.index(battle.recipe_2[i]), t.index(battle.recipe_1[i]))\n",
        "    data[battle.user_id[i]].append(el)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G= nx.DiGraph()\n",
        "G.add_edges_from(data[2])\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.savefig('comparison result: user=2.png')\n",
        "plt.show()\n",
        "##nx.draw(graph, with_labels=True)\n",
        "##plt.savefig(\"path.png\")"
      ],
      "metadata": {
        "id": "d6tB9pjEMngt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKUedQbH4kaZ"
      },
      "outputs": [],
      "source": [
        "def user_preference(data,alpha):\n",
        "    preferences = []\n",
        "    for user, comps in data.items():\n",
        "        params = choix.opt_pairwise(30, data[user],alpha=alpha)\n",
        "        preferences.append(params)\n",
        "    \n",
        "    return preferences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphas=[1e-4, 0.001,0.01,0.1]\n",
        "UR=[]\n",
        "for alpha in alphas:\n",
        "  rank_opt=user_preference(data,alpha)\n",
        "  UR.append(rank_opt)\n",
        "#DataFrame(rank_opt).to_excel('U_R_by_opt.xlsx')\n"
      ],
      "metadata": {
        "id": "0ZGneL95JkxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UR[3][2]"
      ],
      "metadata": {
        "id": "zZ2h6bx10bbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2KamUXH4kaZ"
      },
      "source": [
        "## 2.2 User Preferences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Reciple profile: RF"
      ],
      "metadata": {
        "id": "6ppVCKmTeo5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a recipe-feature matrix\n",
        "rf_time=pd.get_dummies(rf['preparation_time_for_2'])\n",
        "rf_cui=pd.get_dummies(rf['cuisine_name'])\n",
        "rf_carb=pd.get_dummies(rf['main_carb_name']) #some labels can be combined\n",
        "rf_spice=pd.get_dummies(rf['spice_level'])\n",
        "rf_protein=pd.get_dummies(rf['protein_name'])\n",
        "rf_protein_category=pd.get_dummies(rf['protein_category_name'])\n",
        "rf_dish_health = rf[['BBQ','Burger', 'Sandwich', 'Hotdog', 'Tacos', 'Pasta', 'Roast', 'Wraps',\n",
        "       'Pie', 'Soya', 'Curry', 'Burritos', 'Pizza', 'Dal', 'Chowder',\n",
        "       'Gnocchi', 'Laksa', 'Risotto', 'Stew', 'Stir Fry', 'Pilaf', 'Tray Bake',\n",
        "       'Finger food', 'Oven', 'Salads', 'Stove top', 'bowl food', 'Protein',\n",
        "       'Veg', 'Soups', 'Health Exception', 'Healthy', 'Low Cal', 'Low Carb',\n",
        "       'Not Healthy', 'Wholegrain']]\n",
        "R_F = pd.concat([rf_cui,rf_carb,rf_spice,rf_protein,rf_protein_category,rf_dish_health,rf_time],axis=1)\n"
      ],
      "metadata": {
        "id": "nQAgLwP-ejQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gnocchi\n",
        "R_F['Gnocchi_all']=np.sum(np.array(R_F['Gnocchi']),axis=1)\n",
        "f7 = lambda s: 1 if int(s['Gnocchi_all'])>=1 else 0\n",
        "R_F['Gnocchi_all'] = R_F.apply(f7, axis=1)\n",
        "# Fruit & Vegetables\n",
        "R_F['Fruit_Vegetables_all']=np.sum(np.array(R_F['Fruit & Vegetables']),axis=1)\n",
        "f8 = lambda s: 1 if int(s['Fruit_Vegetables_all'])>=1 else 0\n",
        "R_F['Fruit_Vegetables_all'] = R_F.apply(f8, axis=1)\n",
        "# Nuts & Seeds\n",
        "R_F['Nuts_Seeds_all']=np.sum(np.array(R_F['Nuts & Seeds']),axis=1)\n",
        "f9 = lambda s: 1 if int(s['Nuts_Seeds_all'])>=1 else 0\n",
        "R_F['Nuts_Seeds_all'] = R_F.apply(f9, axis=1)"
      ],
      "metadata": {
        "id": "MeMggYZjeyeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_F.drop(['Gnocchi','Fruit & Vegetables','Nuts & Seeds'],axis=1,inplace=True)\n",
        "R_F.rename(columns= {'Gnocchi_all': 'Gnocchi', 'Fruit_Vegetables_all':'Fruit & Vegetables',\n",
        "                    'Nuts_Seeds_all':'Nuts & Seeds'}, inplace=True)"
      ],
      "metadata": {
        "id": "PGNbHBzHe1Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate similarity between i and j\n",
        "sim=cosine_similarity(R_F)\n",
        "# draw a correlation figure"
      ],
      "metadata": {
        "id": "EmV_Vok3e6iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(R_F.shape)\n",
        "np.array(R_F)[0]"
      ],
      "metadata": {
        "id": "QMZVZHB51ESW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 User preferences Matrix : User-Feature = User-Item * Item-Feature"
      ],
      "metadata": {
        "id": "KKld258UfO7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_UF(U_R, R_F):\n",
        "  U_F=DataFrame(np.dot(U_R,R_F.iloc[:30,:]))\n",
        "  U_F.columns = list(R_F.columns)\n",
        "  return U_F\n"
      ],
      "metadata": {
        "id": "TwuAktkiW44Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UF=[]\n",
        "for i in UR:\n",
        "  df_rank_opt=DataFrame(i)\n",
        "  U_F_opt=create_UF(df_rank_opt, R_F)\n",
        "  UF.append(U_F_opt)\n",
        "#U_F_opt.to_excel('U_F_opt.xlsx')\n"
      ],
      "metadata": {
        "id": "FtLo8fwYXi2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(UF[3].shape)\n",
        "np.array(UF[3])"
      ],
      "metadata": {
        "id": "cCfi6Vnu2WlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Learning to rank"
      ],
      "metadata": {
        "id": "UkQXDEpMrdUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1 MCDA"
      ],
      "metadata": {
        "id": "DHiws7ftrkz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain each recipes' utility for each user by  additive value function approach\n",
        "AVF=[]\n",
        "for uf in UF:\n",
        "  u_avf=np.dot(uf,R_F.T)\n",
        "  R_all_avf=DataFrame(u_avf.argsort()[:,::-1])\n",
        "  AVF.append(R_all_avf)"
      ],
      "metadata": {
        "id": "H_2pDWFTUd3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(AVF[3].shape)\n",
        "np.array(AVF[3])"
      ],
      "metadata": {
        "id": "nex2OKvS3jeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2 LightGBM"
      ],
      "metadata": {
        "id": "CegQE_uM5FXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2.1 Construct data (X, y)"
      ],
      "metadata": {
        "id": "TfQvRBnvZqdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create user features\n",
        "ranking=DataFrame(UR[3]).reset_index()\n",
        "ranking=ranking.melt(id_vars='index', var_name='item_id',value_name='rating').rename(columns = {\"index\" : 'user_id'})\n",
        "ranking=ranking.sort_values(by=['user_id','item_id'],ascending=True).reset_index(drop=True)\n",
        "ranking['ranking']=ranking['rating'].groupby(ranking['user_id']).rank(ascending=1, method='dense')\n",
        "ranking['rating_mean'] = ranking.groupby('user_id')['rating'].transform('mean')\n",
        "ranking['ranking_mean'] = ranking.groupby('user_id')['ranking'].transform('mean')"
      ],
      "metadata": {
        "id": "dH73i0rZ5D7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add columns: mactch(user-recipe)\n",
        "# convert the value of UF to Max-Mix [-1,1]\n",
        "df = DataFrame(UF[3]).T\n",
        "user_max= df.max()\n",
        "user_min= df.min()\n",
        "df[df>0]=df[df>0]/user_max\n",
        "df[df<0]=-df[df<0]/user_min\n",
        "df_U_F=df.T\n",
        "#  calculate mactch(U-F, R-F)\n",
        "ur_Cos=cosine_similarity(df_U_F,R_F)\n",
        "# add the value into ranking dataframe\n",
        "f10 = lambda s: ur_Cos[int(s.user_id)][int(s.item_id)]\n",
        "ranking['match_between_user_recipe'] = ranking.apply(f10, axis=1)"
      ],
      "metadata": {
        "id": "vh8fHTw8-wVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # add coulumns: utility(user-recipe)\n",
        "f11 = lambda s: u_avf[int(s.user_id)][int(s.item_id)]\n",
        "ranking['utility_between_user_recipe'] = ranking.apply(f11, axis=1)"
      ],
      "metadata": {
        "id": "6GA6OxsAJXHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge recipe and ranking\n",
        "merged_df = rf.merge(ranking, left_on='item_id', right_on='item_id', how='inner')\n",
        "print(merged_df.shape)\n",
        "merged_df.head()"
      ],
      "metadata": {
        "id": "xWycPhnQ_cm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2.2 Train model"
      ],
      "metadata": {
        "id": "FFD8lCQH_6g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random split\n",
        "train, test = train_test_split(merged_df, test_size=0.2, random_state=SEED)\n",
        "print('train shape: ',train.shape)\n",
        "print('test shape: ',test.shape)"
      ],
      "metadata": {
        "id": "oAtWL0cxAEuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['preparation_time_for_2',\n",
        "       'cuisine_name', 'main_carb_name', 'spice_level', 'protein_name',\n",
        "       'protein_category_name', 'BBQ', 'Burger', 'Sandwich', 'Hotdog', 'Tacos',\n",
        "       'Pasta', 'Roast', 'Wraps', 'Pie', 'Soya', 'Curry', 'Burritos', 'Pizza',\n",
        "       'Dal', 'Chowder', 'Gnocchi', 'Laksa', 'Risotto', 'Stew', 'Stir Fry',\n",
        "       'Pilaf', 'Tray Bake', 'Finger food', 'Oven', 'Salads', 'Stove top',\n",
        "       'bowl food', 'Protein', 'Veg', 'Soups', 'Health Exception', 'Healthy',\n",
        "       'Low Cal', 'Low Carb', 'Not Healthy', 'Wholegrain','rating_mean','ranking_mean','match_between_user_recipe'\n",
        "           ]\n",
        "feature2=['preparation_time_for_2',\n",
        "       'cuisine_name', 'main_carb_name', 'spice_level', 'protein_name',\n",
        "       'protein_category_name', 'BBQ', 'Burger', 'Sandwich', 'Hotdog', 'Tacos',\n",
        "       'Pasta', 'Roast', 'Wraps', 'Pie', 'Soya', 'Curry', 'Burritos', 'Pizza',\n",
        "       'Dal', 'Chowder', 'Gnocchi', 'Laksa', 'Risotto', 'Stew', 'Stir Fry',\n",
        "       'Pilaf', 'Tray Bake', 'Finger food', 'Oven', 'Salads', 'Stove top',\n",
        "       'bowl food', 'Protein', 'Veg', 'Soups', 'Health Exception', 'Healthy',\n",
        "       'Low Cal', 'Low Carb', 'Not Healthy', 'Wholegrain']\n",
        "user_col = 'user_id'\n",
        "item_col = 'item_id'\n",
        "target_col = 'ranking'"
      ],
      "metadata": {
        "id": "j9pNrO4RAIlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.sort_values('user_id').reset_index(drop=True)\n",
        "test = test.sort_values('user_id').reset_index(drop=True)"
      ],
      "metadata": {
        "id": "p0UCJI_jAMd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paramater: 'group'\n",
        "train_query = train[user_col].value_counts().sort_index()\n",
        "test_query = test[user_col].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "JDqNdT4IAPS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 2 with user, user-recipe features"
      ],
      "metadata": {
        "id": "nq-TVbCeu6Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try parameter tuning\n",
        "def objective(trial):\n",
        "    # search param\n",
        "    param = {\n",
        "        'reg_alpha': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1), \n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), \n",
        "    }\n",
        "     \n",
        "    \n",
        "    #train model\n",
        "    model = lgb.LGBMRanker(n_estimators=1000, **param, random_state=SEED,)\n",
        "    model.fit(\n",
        "        train[features],\n",
        "        train[target_col],\n",
        "        categorical_feature=['preparation_time_for_2','cuisine_name','main_carb_name',\n",
        "                             'spice_level','protein_name','protein_category_name'],\n",
        "        group=train_query,\n",
        "        eval_set=[(test[features], test[target_col])],\n",
        "        eval_group=[list(test_query)],\n",
        "        eval_at=[1, 3, 5, 10, 20], # calc validation ndcg@1,3,5,10,20\n",
        "        early_stopping_rounds=50,\n",
        "        verbose=10\n",
        "    )\n",
        "    \n",
        "    # maximize mean ndcg\n",
        "    scores = []\n",
        "    for name, score in model.best_score_['valid_0'].items():\n",
        "        scores.append(score)\n",
        "    return np.mean(scores)\n",
        " \n",
        "study = optuna.create_study(direction='maximize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=SEED) #fix random seed\n",
        "                           )\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "uC8HtYImARel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "metadata": {
        "id": "nZMSFIzZA8v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train with best params\n",
        "best_params = study.best_trial.params\n",
        "model = lgb.LGBMRanker(n_estimators=1000, **best_params, random_state=SEED,)\n",
        "model.fit(\n",
        "    train[features],\n",
        "    train[target_col],\n",
        "    categorical_feature=['preparation_time_for_2','cuisine_name','main_carb_name',\n",
        "                             'spice_level','protein_name','protein_category_name'],\n",
        "    group=train_query,\n",
        "    eval_set=[(test[features], test[target_col])],\n",
        "    eval_group=[list(test_query)],\n",
        "    eval_at=[1, 3, 5, 10, 20],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=10\n",
        ")"
      ],
      "metadata": {
        "id": "vuals-01A_QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature imporance\n",
        "plt.figure(figsize=(17, 7))\n",
        "df_plt = pd.DataFrame({'feature_name': features, 'feature_importance': model.feature_importances_})\n",
        "df_plt.sort_values('feature_importance', ascending=False, inplace=True)\n",
        "sns.barplot(x=\"feature_importance\", y=\"feature_name\", data=df_plt)\n",
        "plt.title('feature importance')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance_utility(ur)4.png')"
      ],
      "metadata": {
        "id": "4tWhFt_zBJg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 1 with only recipe features"
      ],
      "metadata": {
        "id": "lkIt7lAdvH4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try parameter tuning\n",
        "def objective(trial):\n",
        "    # search param\n",
        "    param = {\n",
        "        'reg_alpha': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1), \n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100), \n",
        "    }\n",
        "     \n",
        "    \n",
        "    #train model\n",
        "    model2 = lgb.LGBMRanker(n_estimators=1000, **param, random_state=SEED,)\n",
        "    model2.fit(\n",
        "        train[feature2],\n",
        "        train[target_col],\n",
        "        categorical_feature=['preparation_time_for_2','cuisine_name','main_carb_name',\n",
        "                             'spice_level','protein_name','protein_category_name'],\n",
        "        group=train_query,\n",
        "        eval_set=[(test[feature2], test[target_col])],\n",
        "        eval_group=[list(test_query)],\n",
        "        eval_at=[1, 3, 5, 10, 20], # calc validation ndcg@1,3,5,10,20\n",
        "        early_stopping_rounds=50,\n",
        "        verbose=10\n",
        "    )\n",
        "    \n",
        "    # maximize mean ndcg\n",
        "    scores = []\n",
        "    for name, score in model2.best_score_['valid_0'].items():\n",
        "        scores.append(score)\n",
        "    return np.mean(scores)\n",
        " \n",
        "study = optuna.create_study(direction='maximize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=SEED) #fix random seed\n",
        "                           )\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "XlhWG_iWvMIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "metadata": {
        "id": "MqKfdTaJwB9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train with best params\n",
        "best_params2 = study.best_trial.params\n",
        "model2 = lgb.LGBMRanker(n_estimators=1000, **best_params2, random_state=SEED,)\n",
        "model2.fit(\n",
        "    train[feature2],\n",
        "    train[target_col],\n",
        "    categorical_feature=['preparation_time_for_2','cuisine_name','main_carb_name',\n",
        "                             'spice_level','protein_name','protein_category_name'],\n",
        "    group=train_query,\n",
        "    eval_set=[(test[feature2], test[target_col])],\n",
        "    eval_group=[list(test_query)],\n",
        "    eval_at=[1, 3, 5, 10, 20],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=10\n",
        ")"
      ],
      "metadata": {
        "id": "p6o7x6-FwWxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature imporance\n",
        "plt.figure(figsize=(17, 7))\n",
        "df_plt = pd.DataFrame({'feature_name': feature2, 'feature_importance': model2.feature_importances_})\n",
        "df_plt.sort_values('feature_importance', ascending=False, inplace=True)\n",
        "sns.barplot(x=\"feature_importance\", y=\"feature_name\", data=df_plt)\n",
        "plt.title('feature importance without user features')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance_no_uf.png')"
      ],
      "metadata": {
        "id": "2TAHz1HpwxEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3.2.3 ranking"
      ],
      "metadata": {
        "id": "04GWWOVTCOYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model2"
      ],
      "metadata": {
        "id": "IVvsITNux6Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend recipes to user\n",
        "def recommend_for_user(u, m, r, uf, match):\n",
        "    user_df = uf.query('user_id==@u')\n",
        "    r['ranking_mean']=user_df.ranking_mean.values[0]\n",
        "    r['rating_mean']=user_df.rating_mean.values[0]\n",
        "    # add match_between_user_recipe\n",
        "    f11 = lambda s: match[u][int(s.item_id)]\n",
        "    r['match_between_user_recipe'] = r.apply(f11, axis=1)\n",
        "\n",
        "    # recommend\n",
        "    preds = m.predict(r[features])    \n",
        "    topk_idx = np.argsort(preds)[::-1]\n",
        " \n",
        "\n",
        "    return topk_idx"
      ],
      "metadata": {
        "id": "7AZucS35CM1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_feature=ranking[['ranking_mean','rating_mean']].groupby(ranking['user_id']).mean()\n",
        "R_all_LGBM = []\n",
        "for user_id in range(df_U_F.shape[0]):\n",
        "  rl=recommend_for_user(user_id, model, rf, user_feature,ur_Cos )\n",
        "  R_all_LGBM.append(rl)\n",
        "  "
      ],
      "metadata": {
        "id": "VXSQghkUCbV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DataFrame(R_all_LGBM).shape)\n",
        "np.array(DataFrame(R_all_LGBM))"
      ],
      "metadata": {
        "id": "7cqa0cmdqKHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model 1"
      ],
      "metadata": {
        "id": "7Z5K5_TBx9yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend recipes to user\n",
        "def recommend_for_user2(u, m, r):\n",
        "\n",
        "    # recommend\n",
        "    preds = m.predict(r[feature2])    \n",
        "    topk_idx = np.argsort(preds)[::-1]\n",
        " \n",
        "\n",
        "    return topk_idx"
      ],
      "metadata": {
        "id": "ele7Z9MByPbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_all_LGBM2 = []\n",
        "for user_id in range(df_U_F.shape[0]):\n",
        "  rl=recommend_for_user2(user_id, model2, rf)\n",
        "  R_all_LGBM2.append(rl)"
      ],
      "metadata": {
        "id": "DWk7jl3ZyBwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_all_LGBM2=DataFrame(R_all_LGBM2)\n",
        "print(R_all_LGBM2.shape)\n",
        "np.array(R_all_LGBM2)"
      ],
      "metadata": {
        "id": "Zc0G02RBzhNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhnSYxp44kao"
      },
      "source": [
        "# 3. Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V37q7gi74kao"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mjtA7SV4kao"
      },
      "outputs": [],
      "source": [
        "# Evaluation matrics: precision, recall, lift score, weight_score, diversity\n",
        "def precision_score(R,O,k):\n",
        "    inter = [i for i in R if i in O]\n",
        "    return len(inter)/k\n",
        "\n",
        "def recall_score(R,O):\n",
        "    inter = [i for i in O if i in R]\n",
        "    return len(inter)/len(O)\n",
        "\n",
        "def lift_score(precision, O):\n",
        "    lift = precision / (len(O)/3047)\n",
        "    return lift\n",
        "\n",
        "def weighted_score(R,O):\n",
        "    inter = [i for i in R if i in O]\n",
        "    swp=0\n",
        "    iswp=0\n",
        "    for i in inter:\n",
        "        swp += 1/ np.log(R.index(i)+2)\n",
        "        iswp += 1/ np.log(inter.index(i)+2)\n",
        "    if iswp==0:\n",
        "      nswp=0\n",
        "    else:\n",
        "      nswp = swp/iswp\n",
        "    \n",
        "    return swp, nswp\n",
        "\n",
        "def diversity_score(R,sim,k):\n",
        "    dif=0\n",
        "    for pair in list(combinations(R, 2)):\n",
        "        dif += sim[pair[0]][pair[1]]\n",
        "    div=1- (dif*2)/(k*(k-1))\n",
        "    return div"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odcaPiXO4kao"
      },
      "source": [
        "## 3.1.1 model 3 - MCDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3nXlrMP4kaq"
      },
      "outputs": [],
      "source": [
        "ordered = order2[order2.ordered==1]\n",
        "for avf in AVF:\n",
        "  print('---------------------')\n",
        "  for k in [50, 100, 200, 300]:\n",
        "      precision_all=0\n",
        "      recall_all = 0\n",
        "      lift_all = 0\n",
        "      swp_all = 0\n",
        "      nswp_all = 0\n",
        "      diversity_all=0\n",
        "      \n",
        "      \n",
        "      for user_id in range(avf.shape[0]):\n",
        "          user=user_id\n",
        "          recommend_df = avf.iloc[user,:k]\n",
        "          R=list(recommend_df)\n",
        "          O=list(ordered[(ordered.user_id==user)].item_id)\n",
        "          # calculate 5 evaluation metrics\n",
        "          precision=precision_score(R, O, k)\n",
        "          recall=recall_score(R,O)\n",
        "          lift= lift_score(precision, O)\n",
        "          swp, nswp =  weighted_score(R,O)\n",
        "          diversity=diversity_score(R,sim,k)\n",
        "\n",
        "          precision_all += precision\n",
        "          recall_all += recall\n",
        "          lift_all += lift\n",
        "          swp_all += swp\n",
        "          nswp_all += nswp\n",
        "          diversity_all += diversity\n",
        "\n",
        "      precision_mean = precision_all/ (user_info.shape[0])\n",
        "      recall_mean = recall_all/ (user_info.shape[0])\n",
        "      lift_mean = lift_all/ (user_info.shape[0])\n",
        "      swp_mean = swp_all/ (user_info.shape[0])\n",
        "      nswp_mean = nswp_all/ (user_info.shape[0])\n",
        "      diversity_mean = diversity_all/ (user_info.shape[0])\n",
        "\n",
        "      print(f'Top {k}, precision: {precision_mean}')\n",
        "      print(f'Top {k}, recall: {recall_mean}')\n",
        "      print(f'Top {k}, lift: {lift_mean}')\n",
        "      print(f'Top {k}, swp: {swp_mean}')\n",
        "      print(f'Top {k}, nswp: {nswp_mean}')\n",
        "      print(f'Top {k}, diversity: {diversity_mean}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1.2 LightGBM Ranker"
      ],
      "metadata": {
        "id": "nlcr4GZ6Bsiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 2"
      ],
      "metadata": {
        "id": "jASw20EZJB9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordered = order2[order2.ordered==1]\n",
        "R_all_LGBM=DataFrame(R_all_LGBM)\n",
        "\n",
        "for k in [50, 100, 200, 300]:\n",
        "  precision_all=0\n",
        "  recall_all = 0\n",
        "  lift_all = 0\n",
        "  swp_all = 0\n",
        "  nswp_all = 0\n",
        "  diversity_all=0\n",
        "\n",
        "  for user_id in range(R_all_LGBM.shape[0]):\n",
        "    user=user_id\n",
        "    recommend_df = R_all_LGBM.iloc[user,:k]\n",
        "    R=list(recommend_df)\n",
        "    O=list(ordered[(ordered.user_id==user)].item_id)\n",
        "    # calculate 5 evaluation metrics\n",
        "    precision=precision_score(R, O, k)\n",
        "    recall=recall_score(R,O)\n",
        "    lift= lift_score(precision, O)\n",
        "    swp, nswp =  weighted_score(R,O)\n",
        "    diversity=diversity_score(R,sim,k)\n",
        "\n",
        "    precision_all += precision\n",
        "    recall_all += recall\n",
        "    lift_all += lift\n",
        "    swp_all += swp\n",
        "    nswp_all += nswp\n",
        "    diversity_all += diversity\n",
        "\n",
        "  precision_mean = precision_all/ (user_info.shape[0])\n",
        "  recall_mean = recall_all/ (user_info.shape[0])\n",
        "  lift_mean = lift_all/ (user_info.shape[0])\n",
        "  swp_mean = swp_all/ (user_info.shape[0])\n",
        "  nswp_mean = nswp_all/ (user_info.shape[0])\n",
        "  diversity_mean = diversity_all/ (user_info.shape[0])\n",
        "\n",
        "  print(f'Top {k}, precision: {precision_mean}')\n",
        "  print(f'Top {k}, recall: {recall_mean}')\n",
        "  print(f'Top {k}, lift: {lift_mean}')\n",
        "  print(f'Top {k}, swp: {swp_mean}')\n",
        "  print(f'Top {k}, nswp: {nswp_mean}')\n",
        "  print(f'Top {k}, diversity: {diversity_mean}')"
      ],
      "metadata": {
        "id": "ILoL_yBLuAXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 1"
      ],
      "metadata": {
        "id": "csQSWGBQtxHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ordered = order2[order2.ordered==1]\n",
        "R_all_LGBM2=DataFrame(R_all_LGBM2)\n",
        "\n",
        "for k in [50, 100, 200, 300]:\n",
        "  precision_all=0\n",
        "  recall_all = 0\n",
        "  lift_all = 0\n",
        "  swp_all = 0\n",
        "  nswp_all = 0\n",
        "  diversity_all=0\n",
        "\n",
        "  for user_id in range(R_all_LGBM2.shape[0]):\n",
        "    user=user_id\n",
        "    recommend_df = R_all_LGBM2.iloc[user,:k]\n",
        "    R=list(recommend_df)\n",
        "    O=list(ordered[(ordered.user_id==user)].item_id)\n",
        "    # calculate 5 evaluation metrics\n",
        "    precision=precision_score(R, O, k)\n",
        "    recall=recall_score(R,O)\n",
        "    lift= lift_score(precision, O)\n",
        "    swp, nswp =  weighted_score(R,O)\n",
        "    diversity=diversity_score(R,sim,k)\n",
        "\n",
        "    precision_all += precision\n",
        "    recall_all += recall\n",
        "    lift_all += lift\n",
        "    swp_all += swp\n",
        "    nswp_all += nswp\n",
        "    diversity_all += diversity\n",
        "\n",
        "  precision_mean = precision_all/ (user_info.shape[0])\n",
        "  recall_mean = recall_all/ (user_info.shape[0])\n",
        "  lift_mean = lift_all/ (user_info.shape[0])\n",
        "  swp_mean = swp_all/ (user_info.shape[0])\n",
        "  nswp_mean = nswp_all/ (user_info.shape[0])\n",
        "  diversity_mean = diversity_all/ (user_info.shape[0])\n",
        "\n",
        "  print(f'Top {k}, precision: {precision_mean}')\n",
        "  print(f'Top {k}, recall: {recall_mean}')\n",
        "  print(f'Top {k}, lift: {lift_mean}')\n",
        "  print(f'Top {k}, swp: {swp_mean}')\n",
        "  print(f'Top {k}, nswp: {nswp_mean}')\n",
        "  print(f'Top {k}, diversity: {diversity_mean}')"
      ],
      "metadata": {
        "id": "Adyaw-cxBxcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 User profile"
      ],
      "metadata": {
        "id": "srxjPZjOC2S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Max-Mix [-1,1]\n",
        "df = DataFrame(UF[3]).T\n",
        "user_max= df.max()\n",
        "user_min= df.min()\n",
        "df[df>0]=df[df>0]/user_max\n",
        "df[df<0]=-df[df<0]/user_min\n",
        "df_U_F=df.T"
      ],
      "metadata": {
        "id": "9WrczabiIZri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_profile(U_F, user):\n",
        "    feature=np.array((U_F.columns))\n",
        "    uf = U_F.iloc[user,:]\n",
        "    idx=uf.values.argsort()[::-1]\n",
        "    sorted_feature=feature[idx]\n",
        "    sorted_uf=sorted(uf, reverse=True)\n",
        "    df = pd.DataFrame({'Feature':sorted_feature, 'Params':sorted_uf})\n",
        "    return df\n",
        "\n",
        "def user_prefered_feature(df_feature, User, user_id):\n",
        "    u=User.merge(df_feature[['feature', 'type']], how = 'inner',left_on='Feature', right_on = 'feature')\n",
        "    u.drop(['feature'],axis=1,inplace=True)\n",
        "    fav_feature=u[u['Params']>0]\n",
        "    #fav_feature.drop(['feature'],inplace=True)\n",
        "    fav_feature['user_id']=user_id\n",
        "    return fav_feature\n",
        "    "
      ],
      "metadata": {
        "id": "kezc0y8TC4Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_prefered = DataFrame()\n",
        "feature=pd.read_excel('feature3.xlsx')\n",
        "for i in range(df_U_F.shape[0]):\n",
        "    User=user_profile(df_U_F, i)\n",
        "    fav=user_prefered_feature(feature, User, i)\n",
        "    all_user_prefered=pd.concat([all_user_prefered,fav], axis=0)"
      ],
      "metadata": {
        "id": "pT6sl9zVDC11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_users_prefered_feature(user_id,all_user_prefered ):\n",
        "    x=all_user_prefered[all_user_prefered.user_id==user_id].Feature\n",
        "    y=all_user_prefered[all_user_prefered.user_id==user_id].Params\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(x[:10], y[:10],marker='o', alpha=0.5, linewidth=1.5, label=user_id)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Feature') \n",
        "    plt.ylabel('Params')\n",
        "    plt.title(f'Preferred features: user{user_id}')\n",
        "    plt.savefig(f'user={user_id}.png')\n",
        "    plt.show()\n",
        "    return"
      ],
      "metadata": {
        "id": "o0Dz-51nKaPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_users_prefered_feature(2,all_user_prefered)"
      ],
      "metadata": {
        "id": "jlW-FbnjKall"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-yOxURcJvT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MtcfxzRbR2b-",
        "DHiws7ftrkz5",
        "vhnSYxp44kao",
        "EksExk1W2FEa"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}